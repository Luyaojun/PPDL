{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pyrebase\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_TRAINING_IMAGES = 60000\n",
    "NUM_TESTING_IMAGES = 10000\n",
    "IMAGE_SIZE = 28\n",
    "mnist_train_file = '/home/yang/Research/Privacy-preserving-DL/PPDL/DATA/MNIST/mnist_train.tfrecord'\n",
    "mnist_test_file = '/home/yang/Research/Privacy-preserving-DL/PPDL/DATA/MNIST/mnist_test.tfrecord'\n",
    "\n",
    "# parameters\n",
    "batch_size = 500\n",
    "epochs = 3   ## ?? ##\n",
    "epsilon = .1 # privacy budget for each epoch\n",
    "learning_rate = .1\n",
    "grad_bound = .001\n",
    "grad_threshold = .0001  # for SVT\n",
    "grad_upload_ratio = .001 # ratio of parameters for uploading at each iteration\n",
    "grad_upload_num = int((784*64 + 640) * grad_upload_ratio) # number of parameters for uploading at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MnistInputAll(mnist_data_file):\n",
    "  \"\"\"Create operations to read the MNIST input file.\n",
    "  Args:\n",
    "    mnist_data_file: Path of a tfrecord file containing the MNIST images to process.\n",
    "\n",
    "  Returns:\n",
    "    images: A list with the formatted image data. shape [10000, 28*28]\n",
    "    labels: A list with the labels for each image.  shape [10000]\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "      file_queue = tf.train.string_input_producer([mnist_data_file], num_epochs= 1)\n",
    "      reader = tf.TFRecordReader()\n",
    "      _, value = reader.read(file_queue)\n",
    "      example = tf.parse_single_example(\n",
    "          value,\n",
    "          features={\"image/encoded\": tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "                    \"image/class/label\": tf.FixedLenFeature([1], tf.int64)})\n",
    "\n",
    "      image = tf.cast(tf.image.decode_png(example[\"image/encoded\"], channels=1),\n",
    "                      tf.float32)\n",
    "      image = tf.reshape(image, [IMAGE_SIZE * IMAGE_SIZE])\n",
    "      image /= 255\n",
    "      label = tf.cast(example[\"image/class/label\"], dtype=tf.int32)\n",
    "      label = tf.reshape(label, [])\n",
    "\n",
    "      init_op = tf.global_variables_initializer()\n",
    "      init_op2 = tf.local_variables_initializer()\n",
    "      sess.run(init_op)\n",
    "      sess.run(init_op2)\n",
    "      coord = tf.train.Coordinator()\n",
    "      threads = tf.train.start_queue_runners(coord=coord)\n",
    "      images = []\n",
    "      labels = []\n",
    "      try:\n",
    "          while True:\n",
    "              i, l = sess.run([image, label])\n",
    "              i = i.tolist()\n",
    "              images.append(i)\n",
    "              labels.append(l)\n",
    "      except tf.errors.OutOfRangeError, e:\n",
    "          coord.request_stop(e)\n",
    "      finally:\n",
    "          coord.request_stop()\n",
    "          coord.join(threads)\n",
    "\n",
    "      return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_train_file = '/home/yang/Research/Privacy-preserving-DL/PPDL/DATA/MNIST/mnist_train.tfrecord'\n",
    "mnist_test_file = '/home/yang/Research/Privacy-preserving-DL/PPDL/DATA/MNIST/mnist_test.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images, labels = MnistInputAll(mnist_train_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_tensor = tf.convert_to_tensor(images, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(60000, 784) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MnistInput(mnist_data_file, whole = True, start = None, size = None):\n",
    "    \"\"\"Create operations to read the MNIST input file.\n",
    "      Args:\n",
    "        mnist_data_file: Path of a tfrecord file containing the MNIST images to process.\n",
    "        whole: when set to true, return the whole MNIST dataset (training or test set)\n",
    "        start: start index of the first sample in the user dataset\n",
    "        size: size of the user dataset\n",
    "    \n",
    "      Returns:\n",
    "        images: A list with the formatted image data. default shape [10000, 28*28]\n",
    "        labels: A list with the labels for each image. default shape [10000]\n",
    "      \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        file_queue = tf.train.string_input_producer([mnist_data_file], num_epochs= 1)\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, value = reader.read(file_queue)\n",
    "        example = tf.parse_single_example(\n",
    "            value,\n",
    "            features={\"image/encoded\": tf.FixedLenFeature(shape=(), dtype=tf.string),\n",
    "                    \"image/class/label\": tf.FixedLenFeature([1], tf.int64)})\n",
    "\n",
    "        image = tf.cast(tf.image.decode_png(example[\"image/encoded\"], channels=1),\n",
    "                      tf.float32)\n",
    "        image = tf.reshape(image, [IMAGE_SIZE * IMAGE_SIZE])\n",
    "        image /= 255\n",
    "        label = tf.cast(example[\"image/class/label\"], dtype=tf.int32)\n",
    "        label = tf.reshape(label, [])\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        init_op2 = tf.local_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        sess.run(init_op2)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        images = []\n",
    "        labels = []\n",
    "        if whole:\n",
    "            try:\n",
    "                while True:\n",
    "                    i, l = sess.run([image, label])\n",
    "                    i = i.tolist()\n",
    "                    images.append(i)\n",
    "                    labels.append(l)\n",
    "            except tf.errors.OutOfRangeError, e:\n",
    "                coord.request_stop(e)\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "                coord.join(threads)\n",
    "        else:\n",
    "            try:\n",
    "                for k in xrange(start - 1):\n",
    "                    sess.run([image, label])\n",
    "                for k in xrange(start, start + size):\n",
    "                    i, l = sess.run([image, label])\n",
    "                    i = i.tolist()\n",
    "                    images.append(i)\n",
    "                    labels.append(l)\n",
    "            except tf.errors.OutOfRangeError, e:\n",
    "                coord.request_stop(e)\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "                coord.join(threads)\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images, labels = MnistInput(mnist_train_file, whole = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image1, label1 = MnistInput(mnist_train_file, whole = False, start = 10, size = 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
